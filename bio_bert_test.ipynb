{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bio-bert test",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rishi15-t/Bio-Bert-Emebddings/blob/master/bio_bert_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdSYqajWhhs6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, SequentialSampler\n",
        "\n",
        "def GetTextEmbeddings_Bert(dataset, batch_size = 32):\n",
        "  \n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  input_ids = TextTransformation_Bert(dataset['Disease Class'])\n",
        "  sampler = SequentialSampler(input_ids)\n",
        "  dataloader = DataLoader(input_ids, sampler=sampler, batch_size=batch_size)\n",
        "\n",
        "  model = BertMultiLabelClassifier(gen_embeddings = True)\n",
        "  model.to(device)\n",
        "  model.eval()\n",
        "\n",
        "  for num, batch_data in enumerate(dataloader):\n",
        "      print(num) \n",
        "      indexed_tokens, segment_ids , masked_ids = tuple(t for t in batch_data)   \n",
        "      data = indexed_tokens.to(device)\n",
        "      with torch.no_grad():\n",
        "        emdeddings = model(data)\n",
        "\n",
        "  return emdeddings"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLPzBlKkBjZD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "class TextTransformation_Bert(Dataset) :\n",
        "\n",
        "    def __init__(self, text_list, max_input_length = 512):\n",
        "\n",
        "        self.text_list = text_list\n",
        "        self.indexed_tokens = []\n",
        "        self.segment_ids = []\n",
        "        self.masked_ids = []\n",
        "        self.max_input_length = max_input_length\n",
        "\n",
        "    def GetIndexedTokens(self, text):\n",
        "        \n",
        "        tokenizer = AutoTokenizer.from_pretrained(\"monologg/biobert_v1.1_pubmed\")\n",
        "        tokenized_text = tokenizer.tokenize(text)\n",
        "        tokenized_text.append(\"[SEP]\")\n",
        "        tokenized_text.insert(0,\"[CLS]\")\n",
        "        self.indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "        \n",
        "\n",
        "    def GetSegmentIds(self) :\n",
        "        \n",
        "        self.segment_ids = [1] * len(self.indexed_tokens)\n",
        "\n",
        " \n",
        "    def GetMaskedIds(self) :\n",
        "        \n",
        "        self.masked_ids = [1] * len(self.indexed_tokens)\n",
        "\n",
        "\n",
        "    def Padding(self) :\n",
        "\n",
        "        if(len(self.indexed_tokens) < self.max_input_length) :\n",
        "           padding = [0]*(self.max_input_length - len(self.indexed_tokens))\n",
        "           self.indexed_tokens += padding\n",
        "           self.segment_ids += padding\n",
        "           self.masked_ids += padding\n",
        "        else :\n",
        "           del self.indexed_tokens[self.max_input_length:]\n",
        "           del self.segment_ids[self.max_input_length:]\n",
        "           del self.masked_ids[self.max_input_length:]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text_list)\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        text = self.text_list[idx]\n",
        "\n",
        "        self.GetIndexedTokens(text)\n",
        "        self.GetSegmentIds()\n",
        "        self.GetMaskedIds()\n",
        "        self.Padding()\n",
        "        \n",
        "        self.indexed_tokens = torch.tensor(self.indexed_tokens)\n",
        "        self.segment_ids = torch.tensor(self.segment_ids)\n",
        "        self.masked_ids = torch.tensor(self.masked_ids)\n",
        "        \n",
        "        return self.indexed_tokens, self.segment_ids , self.masked_ids"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HNnZBLx85nK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import BertModel, BertConfig\n",
        "from torch import nn\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModelWithLMHead\n",
        "\n",
        "class BertMultiLabelClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden_layer_size = 512, input_size = 768, num_labels = 23, dropout = 0.1, gen_embeddings = False, use_pooled_output = False):\n",
        "\n",
        "        super(BertMultiLabelClassifier, self).__init__()\n",
        "        self.num_labels = num_labels\n",
        "        self.input_size = input_size\n",
        "        self.gen_embeddings = gen_embeddings\n",
        "        self.hidden_layer_size = hidden_layer_size\n",
        "        self.use_pooled_output = use_pooled_output\n",
        "\n",
        " \n",
        "        self.base_model = AutoModelWithLMHead.from_pretrained(\"monologg/biobert_v1.1_pubmed\")\n",
        "        \n",
        "        self.hidden_layer = torch.nn.Linear(self.input_size, self.hidden_layer_size)\n",
        "        self.hidden_activation = torch.nn.ReLU()\n",
        "\n",
        "        self.output_layer = torch.nn.Linear(self.hidden_layer_size, self.num_labels)\n",
        "        self.output_activation = torch.nn.Sigmoid()\n",
        "\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "    def forward(self, indexed_tokens, segment_ids=None, masked_ids=None):\n",
        "        \n",
        "        if(self.gen_embeddings):\n",
        "            if(self.use_pooled_output) :\n",
        "                pooled_output = self.base_model(indexed_tokens, segment_ids, masked_ids)\n",
        "                embeddings = pooled_output[1]\n",
        "                return embeddings\n",
        "            else:\n",
        "                output = self.base_model(indexed_tokens, segment_ids, masked_ids)\n",
        "                return output\n",
        "        else :\n",
        "            embeddings = indexed_tokens\n",
        "        \n",
        "        logits1 = self.hidden_layer(embeddings)\n",
        "        activation1 = self.hidden_activation(logits1)\n",
        "\n",
        "        dropped = self.dropout(activation1)\n",
        "\n",
        "        logits2 = self.output_layer(dropped)\n",
        "        if(self.training) :\n",
        "            return logits2\n",
        "        else :\n",
        "            output = self.output_activation(logits2)\n",
        "            return output\n",
        "\n",
        "\n",
        "    def freeze_base_model(self):\n",
        "        for param in self.base_model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "\n",
        "    def unfreeze_base_model(self):\n",
        "        for param in self.base_model.named_parameters():\n",
        "            param.requires_grad = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlYuKoKKnp_E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "dataset = pd.read_csv('/content/drive/My Drive/BioBert/bio-decagon-effectcategories.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ody0sOTZoXE4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "113ca05f-ad48-4b0f-942f-2c499a681ad0"
      },
      "source": [
        "results = GetTextEmbeddings_Bert(dataset)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mli704lrq0RP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1918a577-293e-4208-a6d3-8fb6e58d0b9c"
      },
      "source": [
        "results[0].shape"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 512, 28996])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_umG3-H1aPc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "d8e2ff38-5948-402d-afcb-c2a8658f7a9c"
      },
      "source": [
        "results"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[-5.6042e-01, -8.3055e-01, -9.6464e-01,  ..., -1.5285e+00,\n",
              "           -4.5190e-01, -1.3522e+00],\n",
              "          [-1.3895e+00, -4.5119e-01,  8.7689e-02,  ..., -2.2046e+00,\n",
              "            1.3513e-01, -1.9077e+00],\n",
              "          [-1.6453e+00, -4.9373e-01, -2.2516e-01,  ..., -1.9045e+00,\n",
              "           -2.4326e-01, -9.7380e-01],\n",
              "          ...,\n",
              "          [-4.5840e-01, -6.5471e-01,  1.9402e-03,  ...,  1.0318e-01,\n",
              "           -7.1608e-01, -4.4111e-02],\n",
              "          [-4.6923e-01, -9.3311e-01,  1.7121e-02,  ..., -2.4800e-02,\n",
              "           -6.8660e-01, -3.4581e-02],\n",
              "          [-8.3014e-02, -5.3442e-01,  3.4464e-01,  ...,  2.0198e-01,\n",
              "           -4.9682e-01,  2.0491e-01]],\n",
              " \n",
              "         [[-4.0068e-01, -6.5658e-01, -8.6402e-01,  ..., -1.4564e+00,\n",
              "           -4.8579e-01, -1.1223e+00],\n",
              "          [-7.6499e-01, -1.0700e-01,  1.9991e-01,  ..., -1.9594e+00,\n",
              "           -2.8680e-01, -1.1505e+00],\n",
              "          [-1.6350e+00, -8.1324e-01, -7.8226e-01,  ..., -2.0649e+00,\n",
              "           -1.0603e+00, -1.4718e+00],\n",
              "          ...,\n",
              "          [-5.2108e-01, -6.4022e-01, -4.3926e-02,  ...,  8.2469e-02,\n",
              "           -7.3407e-01, -8.1033e-02],\n",
              "          [-4.8563e-01, -8.8132e-01, -6.4615e-03,  ..., -2.7914e-02,\n",
              "           -6.5640e-01, -4.7361e-02],\n",
              "          [-1.2364e-01, -5.4655e-01,  2.9075e-01,  ...,  1.6707e-01,\n",
              "           -5.1521e-01,  1.9231e-01]]]),)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AHR5gwpJeR3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model = AutoModelWithLMHead.from_pretrained(\"monologg/biobert_v1.1_pubmed\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1u2jQBkJkqY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "55fcb4e7-343d-4c63-9d90-5ec07fc11e0c"
      },
      "source": [
        "base_model"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForMaskedLM(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (cls): BertOnlyMLMHead(\n",
              "    (predictions): BertLMPredictionHead(\n",
              "      (transform): BertPredictionHeadTransform(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      )\n",
              "      (decoder): Linear(in_features=768, out_features=28996, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aa5YgEA4Jmmw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}